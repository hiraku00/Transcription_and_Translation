時々、人々は大規模な言語モデルを知識ストアとして考える。
これは、多くの情報を記憶するために学習されたもので、おそらくインターネットから取得したものでしょう。
だから、質問をすると、その質問に答えることができるのです。
しかし、私は、大規模言語モデルをより有用に考える方法として、テキストや他の情報源からチャンスを与えることができる推論エンジンとして考えることができると思います。
そして、大規模言語モデルLOMは、インターネットから学習した背景知識を使うかもしれませんが、あなたが与えた新しい情報を使って、質問に答えたり、コンテンツを推論したり、次に何をすべきかを決めたりするのを助けることができます。
そして、LandChainsのエージェント・フレームワークは、そのようなことを期待するものです。
エージェントは、LandChainsの中で私が最も気に入っている部分です。
最もパワフルな部分の一つでもありますが、新しい部分の一つでもあります。
そのため、この分野では誰もが初めて目にするものがたくさん出てきています。
エージェントとは何か、エージェントの作り方や使い方、LandChainに組み込まれている検索エンジンのような様々な種類のツールをエージェントに装備させる方法、さらに独自のツールを作って、エージェントにあらゆるデータストアやAPI、機能を使わせる方法など、この授業はとてもエキサイティングなものになるはずです。
このように、これはエキサイティングな最先端のものですが、すでに新たな重要なユースケースが生まれています。
では、それを見ていきましょう。
さあ、飛び込んでみましょう。
まず、環境変数を設定し、後で使用するものをたくさんインポートします。
次に、言語モデルを初期化します。
そして重要なのは、温度をゼロに設定することです。
これは重要なことで、言語モデルをエージェントの推論エンジンとして使用し、他のデータソースや計算ソースに接続することになります。
そのため、この推論エンジンはできるだけ優秀で正確であることが望まれます。
そのため、ランダム性を排除するためにゼロに設定することにします。
次に、いくつかのツールをロードします。
LLMathツールとWikipediaツールの2つを読み込みます。
LLMathツールは実際にチェーンそのものであり、言語モデルと電卓を組み合わせて数学の問題を解くために使用します。
WikipediaツールはWikipediaに接続するAPIで、Wikipediaに対して検索クエリを実行し、結果を返すことができる。
次に、エージェントを初期化します。
ツール、言語モデル、そしてエージェントタイプでエージェントを初期化します。
ここでは、Chai Zero Shot React descriptionを使用します。
ここで重要なのは、最初のチャットです。
これは、チャットモデルで動作するように最適化されたエージェントです。
そして2つ目は、Reactです。
これは、言語モデルから最高の推論性能を引き出すために設計されたプロンプト技術です。
また、handle parsing error is equals trueを渡すことにします。
これは、言語モデルが、望ましい出力であるアクション入力に解析できないものを出力するかもしれないときに便利です。
この処理は、実際に誤変換されたテキストを言語モデルに戻し、それ自体を修正するように要求します。
そして最後に、verbose equals trueを渡すことにします。
これは、Jupyterノートブックで何が起こっているのかを明確にするために、多くのステップを出力します。
また、ノートブックの後半でグローバルレベルでdebug equals trueを設定し、何が起こっているのかをより詳細に確認できるようにします。
まず、エージェントに数学の質問をしてみます。
300の25%は何ですか？これはとても簡単な質問ですが、何が起こっているのかを理解するのに適しています。
このように、エージェントが実行者チェーンに入ると、まず何をすべきか考えることがわかります。
つまり、思考がある。
そして、アクションを起こします。
このアクションは、アクションとアクションインプットという2つのものに対応するJSONブロブです。
アクションは、使用するツールに対応します。
つまり、ここでは計算機として使用します。
アクションの入力は、そのツールへの入力です。
ここでは、300×0.25という文字列が入力されています。
次に、答えが別の色で表示された観測があることがわかります。
この答えは75.0に等しいという観測は、実際には電卓ツール自体から得られています。
次に、テキストが緑色になったところで言語モデルに戻ります。
質問の答えは、最終的に75.0となりました。
これが出力されたものです。
これは、一時停止して、自分でいろいろな計算問題を試してみるのに良い機会です。
次に、Wikipedia APIを使った例を見てみましょう。
ここでは、Tom Mitchellについて質問してみます。
そして、中間ステップで何をするのかを見てみましょう。
Wikipediaを使うべきと考え、正しく認識していることがわかります。
アクションはWikipediaに等しく、アクションの入力はTomとMitchellに等しいと言います。
今回、黄色で戻ってきた観察結果は、トムとミッチェルのページに対するWikipediaの要約結果です。
ウィキペディアから戻ってきた観察は、実際には2つの結果、2つのページがあります。
最初のものはコンピュータサイエンティスト、2番目のものはオーストラリアのサッカー選手であることがわかります。
この質問に答えるのに必要な情報、つまり機械学習を書いた本の名前は、最初のTom and Mitchellの要約に含まれていることがわかります。
次に、エージェントがこの本についてより多くの情報を調べようとすることがわかります。
そこで、ウィキペディアで機械学習の本を調べます。
これは厳密には必要ではなく、エージェントがまだ完璧に信頼できるわけではないことを示す興味深い例です。
このように調べると、エージェントは答えに必要な情報をすべて持っていると認識し、機械学習で正しい答えを返していることがわかります。
次に紹介するのは、とてもクールな例です。
copilotやchat GPTのコードインタプリタプラグインを有効にしたものを見たことがあると思いますが、彼らは言語モデルを使ってコードを書き、そのコードを実行しています。
そこで、Pythonエージェントを作成し、先ほどと同じllmを使用して、Python REPLツールというツールを持たせます。
REPLは基本的にコードと対話するためのもので、Jupyterノートブックと同じように考えることができます。
エージェントがこのREPLでコードを実行すると、実行され、結果が返ってきて、その結果がエージェントに戻され、次の行動を決めることができます。
このエージェントに解決してもらう問題は、名前のリストを与えて、それをソートするように依頼することです。
Harrison Chase、Lane Chain、llm、Jeff using transformer、gen ai という名前のリストがあるので、まず姓、名の順に並べ替えて、その出力を表示するようにエージェントに依頼します。
重要なのは、結果を実際に見ることができるように、出力を印刷するよう求めていることです。
この出力された文は、後で言語モデルにフィードバックされ、実行したコードの出力について推論できるようになります。
では、実際に試してみましょう。
エージェントエグゼキュータチェーンに入ると、まず、sorted関数を使って顧客をリストアップできることに気づきます。
そのため、アクションとアクション入力の書式が若干異なっているのがわかります。
ここでは、Python REPLを使用するアクションと、このリストに等しい顧客を最初に書き出すアクションの入力が表示されるコードです。
そして、顧客をソートし、このリストを通して印刷します。
エージェントが何をすべきか考え、コードを書く必要があることに気づくのがわかります。
アクションとアクション入力のフォーマットは、実は以前と少し違っています。
これは別のエージェントタイプを使用しているのです。
アクションにはPython REPLを使い、アクションの入力にはたくさんのコードを使います。
このコードが何をやっているかというと、まず、顧客名をリストアップするための変数を作成しています。
そして、それをソートして新しい変数を作成し、その新しい変数を反復して、私たちが頼んだように各行をプリントアウトしています。
これは名前のリストで、エージェントが完了したことを認識し、これらの名前を返すことがわかります。
プリントアウトされたものから、何が起こっているのかがよくわかりますが、もう少し掘り下げて、レーンチェーンデバッグをtrueに設定して実行してみましょう。
すると、さまざまなチェーンのレベルが出力されるので、それらを調べて、何が起きているのかを見てみましょう。
まず、エージェントエグゼキューターから始めます。
これはトップレベルのエージェントランナで、ここに入力された顧客を姓と名の順に並べ替えて出力していることがわかります。
ここからLLMチェインを呼び出します。
これはエージェントが使っているLLMチェーンです。
LLMチェーンは、プロンプトとLLMの組み合わせを記憶しているわけです。
つまり、この時点では、入力とエージェントのスクラッチパッドしか持っていません。
これについては後で説明します。
また、言語モデルの世代交代を停止するタイミングを知らせるためのストップシーケンスもあります。
次のレベルでは、言語モデルへの正確な呼び出しが表示されます。
どのようなツールにアクセスできるのか、どのように出力をフォーマットするのかといった指示を含む、完全にフォーマットされたプロンプトを見ることができます。
そこから、言語モデルの正確な出力を見ることができます。
テキストキーには、思考と行動とアクションの入力がすべて1つの文字列で表示されています。
次に、LLMのチェーンをラップアップして、そこから外に出て、次に呼び出すのはツールで、ここではツールへの正確な入力を見ることができます。
ツールの名前はPython Ripple、そして入力はこのコードです。
このツールの出力はプリントアウトされた文字列で、これもPython Rippleに何が起こっているのかをプリントアウトするように特別に依頼しているからです。
次にLLMチェーンの次の入力が見えますが、ここでもLLMチェーンはエージェントです。
変数を見てみると、入力はそのままで、我々が求めている高いレベルの目的ですが、エージェントのスクラッチパッドに新しい値が追加されています。
これは、前の世代とツールの出力を組み合わせたもので、言語モデルが以前の状況を理解し、次に何をすべきかを推論するために、これを渡していることがわかります。
次のいくつかのprint文は、言語モデルが基本的に仕事を終えたと認識したときに起こることを説明しています。
ここでは、言語モデルに対する完全なフォーマットのプロンプトが表示され、それが終了したことを認識する応答が表示され、最終的な答えが表示されます。
そして、LLMチェーンから抜け出し、エージェントエグゼキュータから抜けるのが見えます。
これで、エージェントの内部で何が行われているのかがよくわかると思います。
そして、このコーディングエージェントの目的を達成するために、一時停止して、自分なりの目的を設定することができます。
このデバッグモードは、ウィキペディアの例で示したように、何が間違っているのかを強調するために使うこともできます。
時々、エージェントは少しおかしな動きをするので、このような情報があると、何が起こっているのかを理解するのにとても役立ちます。
これまでのところ、LLMチェーンで定義されているツールを使ってきましたが、エージェントの大きな力は、自分の情報源、自分のAPI、自分のデータに接続できることです。
そこで、ここでは、カスタムツールを作成して、好きなものに接続できるようにする方法を説明します。
ここでは、現在のデータが何であるかを教えてくれるツールを作ってみましょう。
まず、このツールデコレーターをインポートします。
これはどんな関数にも適用でき、LLMチェーンが使用できるツールに変えてくれます。
次に、任意のテキスト文字列を揺さぶるtimeという関数を書きます。
これは実際に使うわけではなく、date timeを呼び出すことで今日の日付を返すものです。
関数の名前に加えて、本当に詳細なdoc文字列を書くことにしています。
これは、エージェントがこのツールをいつ呼び出すべきか、どのように呼び出すべきかを知るために使うものだからです。
例えば、ここでは、入力は常に空文字列であるべきだと言っています。
それは私たちが使わないからです。
例えば、検索クエリやSQL文を常に取り込むような関数がある場合など、入力のあり方についてより厳しい要求がある場合は、ここにその旨を明記しておくとよいでしょう。
次に、別のエージェントを作成します。
今回は、既存のツールのリストに時間ツールを追加します。
そして最後に、エージェントを呼び出して、今日の日付が何であるかを尋ねてみましょう。
エージェントがタイムツールを使用する必要があることを認識し、ここで指定されます。
アクションの入力は空文字列になっています。
これは素晴らしいことです。
これは、私たちが指示したことです。
そして、観察結果を返します。
そして最後に、言語モデルがその観測結果を受け取り、ユーザーに応答します。
今日の日付は2023-05-21です。
ここでビデオを一時停止して、違う入力を入れてみてください。
これで、エージェントに関するレッスンは終了です。
これは、より新しく、よりエキサイティングで、より実験的なチェーンの1つです。
ですから、楽しんで使っていただければと思います。
言語モデルを推論エンジンとして使い、さまざまなアクションを起こしたり、他の機能やデータソースに接続したりする方法を紹介できたと思います。
