 Sometimes people think of a large language model as a knowledge store.
As it is learned to memorize a lot of information, maybe off the internet.
So when you ask the question, it can answer the question.
But I think a even more useful way to think of a large language model is sometimes as a reasoning engine in which you can give it chance of text or other sources of information.
And then the large language model, LOM, will maybe use this background knowledge that is learned off the internet, but to use the new information you give it to help you answer questions or reason through content or decide even what to do next.
And that's what LandChains agents framework hopes you to do.
Agents are probably my favorite part of LandChains.
I think they're also one of the most powerful parts, but they're also one of the newer parts.
So we're seeing a lot of stuff emerge here that's really new to everyone in the field.
And so this should be a very exciting lesson as we dive into what agents are, how to create and how to use agents, how to equip them with different types of tools, like search engines that come built into LandChains, and then also how to create your own tools so that you can let agents interact with any data stores, any APIs, any functions that you might want them to.
So this is exciting cutting edge stuff, but already with emerging, important use cases.
So let's look at that.
Let's dive in.
First, we're going to set the environment variables and import a bunch of stuff that we will use later on.
Next, we're going to initialize a language model.
We're going to use Chai OpenAI, and importantly, we're going to set the temperature equal to zero.
This is important because we're going to be using the language model as the reasoning engine of an agent, where it's connecting to other sources of data and computation.
And so we want this reasoning engine to be as good and as precise as possible.
And so we're going to set it to zero to get rid of any randomness that might arise.
Next we're going to load some tools.
The two tools that we're going to load are the LLMath tool and the Wikipedia tool.
The LLMath tool is actually a chain itself, which uses a language model in conjunction with a calculator to do math problems.
The Wikipedia tool is an API that connects to Wikipedia, allowing you to run search queries against Wikipedia and get back results.
Next we're going to initialize an agent.
We're going to initialize the agent with the tools, the language model, and then an agent type.
Here, we're going to use Chai Zero Shot React description.
The important things to note here are our first chat.
This is an agent that has been optimized to work with chat models.
And second, React.
This is a prompting technique designed to get the best reasoning performance out of language models.
We're also going to pass in handle parsing error is equals true.
This is useful when the language model might output something that is not able to be parsed into an action input, which is the desired output.
And this happens will actually pass the misformatted text back to the language model and ask it to correct itself.
And finally, we're going to pass in verbose equals true.
This is going to print out a bunch of steps that makes it really clear to us in the Jupyter notebook what's going on.
We'll also set debug equals true at the global level later on in the notebook so we can see in more detail what exactly is happening.
First we're going to ask the agent a math question.
What is 25% of 300? This is a pretty simple question, but it will be good to understand what exactly is going on.
So we can see here that when it enters the agent executor chain that it first thinks about what it needs to do.
So it has a thought.
It then has an action.
And this action is actually a JSON blob corresponding to two things, an action and an action input.
The action corresponds to the tool to use.
So here is as calculator.
The action input is the input to that tool.
And here it's a string of 300 times 0.25.
Next we can see that there's observation with answer in a separate color.
This observation answer equals 75.0 is actually coming from the calculator tool itself.
Next we go back to the language model when the text turns to green.
We have the answer to the question, final answer 75.0.
And that's the output that we get.
This is a good time to pause and try out different math problems of your own.
Next, we're going to go through an example using the Wikipedia API.
Here we're going to ask the question in about Tom Mitchell.
And we can look at the intermediate steps to see what it does.
We can see once again that it thinks and it correctly realizes that it should use Wikipedia.
It says action equal to Wikipedia and action input equal to Tom and Mitchell.
The observation that comes back in yellow this time and we use different colors to denote different tools is the Wikipedia summary result for the Tom and Mitchell page.
The observation that comes back from Wikipedia is actually two results, two pages as there's two different Tom and Mitchell's.
We can see the first one covers the computer scientist and the second one it looks like it's an Australian footballer.
We can see that the information needed to answer this question, namely the name of the book that he wrote machine learning is present in the summary of the first Tom and Mitchell.
We can see next that the agent tries to look up more information about this book.
So it looks up machine learning book in Wikipedia.
This isn't strictly necessary and it's an interesting example to show how agents aren't perfectly reliably yet.
We can see that after this look up the agent recognizes that it has all the information it needs to answer and responds with the correct answer machine learning.
The next example we're going to go through is a really cool one.
If you've seen things like copilot or even chat GPT with the code interpreter plugin enabled one of the things they're doing is they're using the language model to write code and then executing that code and we can do the same exact thing here.
So we're going to create a Python agent and we're going to use the same llm as before and we're going to give it a tool the Python REPL tool.
A REPL is basically a way to interact with code you can think of it as a Jupyter notebook.
So the agent can execute code with this REPL it will then run and then we'll get back some results and those results will be passed back into the agent so it can decide what to do next.
The problem that we're going to have this agent solve is we're going to give it a list of names and then ask it to sort them.
So you can see here we have a list of names, Harrison Chase, Lane Chain, llm, Jeff using transformer, gen ai and we're going to ask the agent to first sort these names by last name and then first name and then print the output.
Importantly we're asking it to print the output so that it can actually see what the result is.
These printed statements are what's going to be fed back into the language model later on so it can reason about the output of the code that it just ran.
Let's give this a try.
We can see that when we go into the agent executor chain it first realizes that it can use the sorted function to list the customers.
It's using a different agent type under the hood which is why you can see that the action and action input is actually formatted slightly differently.
Here the action that it takes is to use the Python REPL and then the action input that you can see is code where it first writes out customers equals this list.
It then sorts the customers and then it goes through this list and print it.
You can see the agent thinks about what to do and realizes that it needs to write some code.
The format that it's using of action and action input is actually slightly different than before.
It's using a different agent type under the hood.
For the action it's going to use the Python REPL and for the action input it's going to have a bunch of code.
If we look at what this code is doing it's first creating a variable to list out these customer names.
It's then sorting that and creating a new variable and it's then iterating through that new variable and printing out each line just like we asked it to.
We can see that we get the observation back and this is a list of names and then the agent realizes that it's done and it returns these names.
We can see from the stuff that's printed out the high level of what's going on but let's dig a little bit deeper and run this with lane chain debug set to true.
As this prints out all the levels of all the different chains that are going on let's go through them and see what exactly is happening.
So first we start with the agent executor.
This is the top level agent runner and we can see that we have here our input sort of these customers by last name and then first name and print the output.
From here we call an LLM chain.
This is the LLM chain that the agent is using.
So the LLM chain remembers a combination of prompt and an LLM.
So at this point it's only got the input and agent scratch pad.
We'll get back to that later and then some stop sequences to tell the language model when to stop doing its generations.
At the next level we see the exact call to the language model.
So we can see the fully formatted prompt which includes instructions about what tools it has access to as well as how to format its output.
From there we can then see the exact output of the language model.
So we can see the text key where it has the thought and the action and the action input all on one string.
It then wraps up the LLM chain as it exits through there and the next thing that it calls is a tool and here we can see the exact input to the tool.
We can also see the name of the tool Python Ripple and then we can see the input which is this code.
We can then see the output of this tool which is this printed out string and again this happens because we specifically ask the Python Ripple to print out what is going on.
We can then see the next input to the LLM chain which again the LLM chain here is the agent.
So here if you look at the variables there is the input this is unchanged this is the high level objective that we are asking but now there is some new values for agent scratch pad.
You can see here that this is actually a combination of the previous generation plus the tool output and so we are passing this back in so that the language model can understand what happened previously and use that to reason about what to do next.
The next few print statements are covering what happens as the language model realizes that it is basically finished with its job.
So we can see here the fully formatted prompt to the language model the response where it realizes that it is done and it says final answer which here is the sequence that the agent uses to recognize that it is done with its job.
We can then see it exiting the LLM chain and exiting the agent executor.
This should hopefully give you a pretty good idea of what is going on under the hood inside these agents.
This should hopefully give you a pretty good idea of what is going on under the hood and is hopefully instructive as you pause and put your own objectives for this coding agent to try to accomplish.
This debug mode can also be used to highlight what is going wrong as shown above in the Wikipedia example.
Sometimes agents act a little funny and so having all this information is really helpful for understanding what is going on.
So far we have used tools that come defined in LLM chain already but a big power of agents is that you can connect it to your own sources of information, your own APIs, your own data.
So here we are going to go over how you can create a custom tool so that you can connect it to whatever you want.
Let's make a tool that is going to tell us what the current data is.
First, we are going to import this tool decorator.
This can be applied to any function and it turns it into a tool that LLM chain can use.
Next, we are going to write a function called time which shakes in any text string.
We are not really going to use that and it is going to return today's date by calling date time.
In addition to the name of the function, we are also going to write a really detailed doc string.
That's because this is what the agent will use to know when it should call this tool and how it should call this tool.
For example, here we say that the input should always be an empty string.
That's because we don't use it.
If we have more stringent requirements on what the input should be, for example, if we have a function that should always take in a search query or a SQL statement, you'll want to make sure to mention that here.
We're now going to create another agent.
This time we're adding the time tool to the list of existing tools.
And finally, let's call the agent and ask it what the date today is.
It recognizes that it needs to use the time tool, which specifies here.
It has the action input as an empty string.
This is great.
This is what we told it to do.
And then it returns with an observation.
And then finally, the language model takes that observation and responds to the user.
Today's date is 2023-05-21.
You should pause the video here and try putting in different inputs.
This wraps up the lessons on agents.
This is one of the newer and more exciting and more experimental pieces of chain.
So I hope you enjoy using it.
Hopefully it showed you how you can use a language model as a reasoning engine to take different actions and connect to other functions and data sources.