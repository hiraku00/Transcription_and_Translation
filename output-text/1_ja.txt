レッスン1では、モデル、プロンプト、パーサーについて説明します。
モデルとは、その多くを支える言語モデルのことですね。
プロンプトは、モデルに渡す入力を作成するスタイルを指します。
そして、パーサーはその反対側です。
モデルの出力をより構造化されたフォーマットにパースし、それを使って下流で何かできるようにすることです。
ですから、LMを使ってアプリケーションを構築する場合、多くの場合、再利用可能なモデルになっているはずです。
Lanchingは、このような操作を行うための簡単なアトラクションセットを提供します。
それでは、早速、モデル、プロンプト、パーサーについて見ていきましょう。
まず始めに、静的なコードを少し紹介します。
OSをインポートし、OpenAIをインポートし、OpenAIのシークレットキーを読み込むことにしています。
OpenAIのライブラリは、私のJupyterノートブック環境にすでにインストールされています。
これをローカルで実行しているのですが、あなたはまだOpenAIをインストールしていませんね。
それを実行する必要があるかもしれない。
Bank PIPはOpenAIをインストールしますが、ここではそれをするつもりはありません。
それから、これはヘルパー関数です。
これは、OpenAIのEther-for-Fitと一緒に、チャットGPT-promangering for developer scoreをオフにしているのを見たことがあるかもしれないヘルパー関数と非常によく似ているのです。
このヘルパー機能を使えば、1＋1の完成度を求めることができ、チャットGPT、厳密にはモデルGPT-3.5を呼び出してこのように答えを返してくれます。
さて、プロンプトとポーズのモデルに対するランチャンの抽象化を動機付けるために、英語以外の言語で顧客からメールを受け取ったとします。
これがアクセス可能であることを確認するために、私が使用する他の言語は、顧客がいる英語の海賊語です。
私たちはそれをオフにブレンドし、スムージーと私の台所の壁にスプラットすることを発狂するだろう。
さらに悪いことに、キッチンをきれいにする費用は保証の対象外なんだ。
今すぐあなたの助けが必要なんです、あなた。
というわけで、このLOMに、落ち着いた敬語でアメリカ英語に翻訳してもらうことにします。
だから、私はスタイルを穏やかで尊敬に満ちたトーンのアメリカ英語に設定するつもりです。
そして、実際にこれを実現するために、以前にプロンプトを少し見たことがあるのなら、指示のあるF文字列を使ってプロンプトを指定し、トリプルバクティクスで区切られたテキストをstyleに翻訳し、この2つのスタイルをプラグインすることにします。
そうすると、テキストを翻訳してくださいというプロンプトが生成されるわけです。
ぜひ、ビデオを一時停止してコードをレンダリングし、また、プロンプトを修正してみて、別の出力が得られるかどうか試してみてください。
そうすれば、大規模な言語モデルにプロンプトを出して、応答を得ることができます。
どんな反応が返ってくるか見てみましょう。
英語の海賊のメッセージを、とても丁寧に訳すと、「ブレンダーの火が飛んでしまって、スムージーなどでキッチンの壁を汚してしまって、本当にイライラしています。
今、あなたの助けが本当に必要なんです。
とても素敵な響きですね。
このように、英語だけでなく、フランス語、ドイツ語、日本語など、さまざまな言語でレビューを書いている顧客がいる場合、そのような翻訳を生成するために一連のプロンプトを生成しなければならないことが想像できます。
ランドチェーンを使用して、より便利な方法でこれを行う方法について見てみましょう。
chat open AIをインポートしてみます。
これは、chat GPT APIエンドポイントをランドチェーンで抽象化したものです。
そして、chat goes chat open AIと設定し、chat isを見ると、以下のようにchat GPTモデル（GPT 3.5 turboとも呼ばれる）を使用するオブジェクトが作成されます。
アプリケーションを作るときによくやるのは、温度パラメータをゼロにすることです。
つまり、デフォルトの温度は0.7です。
しかし、実際に温度は0.0に等しく設定し直してみます。
このように温度をゼロに設定することで、出力が少し乱れにくくなります。
次に、テンプレート文字列を次のように定義してみましょう。
テキストを翻訳し、トリプルバティックスでスタイル、スタイルにデリートし、テキストを使用します。
そして、このテンプレートを繰り返し再利用するために、ランドチェーンチャットプロンプトテンプレートをインポートしてみましょう。
そして、先ほど上に書いたテンプレート文字列を使って、プロンプトテンプレートを作ってみます。
このプロンプト・テンプレートから、実際に元のプロンプトを取り出すことができます。
このプロンプトには、スタイルとテキストという2つの入力変数があり、中括弧で囲んであることがわかります。
そして、こちらが指定したオリジナルのテンプレートです。
実際、print this outで、スタイルとテキストという2つの入力変数があることに気づきました。
では、スタイルを指定してみましょう。
これは、お客様のメッセージを翻訳するためのスタイルです。
なので、これを顧客スタイルと呼ぶことにします。
そして、これが先ほどと同じ顧客メールです。
そして今、顧客メッセージを作成すると、これがプロンプトを生成します。
そして、これをspawnと一緒に大きな言語モデルに渡します。
型を見てみると、カスタマーメッセージは実はリストになっています。
リストの最初の要素を見てみると、これがプロンプトを生成していることがわかります。
最後に、このプロセスはOMにプロンプトを出すので、先ほどOpenAIのチャットGPDエンドポイントへの参照と言った、チャットを呼び出します。
そして、顧客対応内容をプリントアウトすると、このように英語の海賊版から丁寧なアメリカ英語に翻訳されたテキストが返ってきます。
もちろん、顧客からのメールが他の言語で書かれているような、他の使用例も想像できます。
このツールは、英語圏の人がメッセージを理解し、返信できるように翻訳するために使用できます。
ビデオを一時停止してコードを実行し、プロンプトを変更して別の出力が得られるかどうか試してみることをお勧めします。
さて、カスタマーサービスが元の言語で顧客に返信することを期待しましょう。
例えば、英語圏のカスタマーサービスエージェントが、これは「Hey there customer warranty does not cover clean spends this for a kitchen because it's your fault that miss user blender by figuring it on the lid tough luck.」と書いたとしましょう。
ほら、非常に丁寧なメッセージではありませんが、これは一度顧客サービスエージェントの一つであるとしましょう。
このサービスメッセージは、この海賊スタイルに翻訳されることを指定するつもりです。
つまり、英語の海賊語で話すような丁寧な口調にしたいわけです。
プロンプトテンプレートを作成したので、そのプロンプトテンプレートを再利用して、オフィスはこのサービススタイルの海賊と指定することができるのです。
そして、テキストは、このサービスの返信です。
そうすると、それがプロンプトになります。
そして、チャージGPTでプロンプトを出すと、このようなレスポンスが返ってきます。
あ、そういえば、mateyさん、保証は経費やギャラリーの掃除は対象外ということをお知らせしておかなければなりませんね。
というようなことを言われ、大変な思いをしました。
では、なぜFストリングではなく、プロンプト・テンプレートを使うのかと思われるかもしれません。
その答えは、洗練されたアプリケーションを構築すると、プロンプトが非常に長く、詳細になることがあるからです。
そのため、プロンプトテンプレートは、良いプロンプトを再利用できるようにするための便利な抽象化手段です。
これは、オンライン学習アプリケーションの学生の提出物を採点するための、比較的長いプロンプトの一例です。
このようなプロンプトは非常に長くなり、まず問題を解き、次に特定のフォーマットで出力し、特定のフォーマットで出力するよう LM に求めることができる。
これをラングチェーンプロンプトで包むことで、このようなプロンプトを再利用しやすくなります。
また、ラングチェーンは要約や質問応答、SQLデータベースへの接続、異なるAPIへの接続など、いくつかの一般的な操作のプロンプトを提供していることが後でわかります。
このように、ラングチェーンに組み込まれたプロンプトを使うことで、独自のプロンプトを設計することなく、アプリケーションを素早く動作させることができます。
ラングチェーンのプロンプトライブラリのもう一つの側面は、出力の一時停止もサポートしていることです。
しかし、LM を使って複雑なアプリケーションを構築する場合、特定のキーワードを使うなど、特定のフォーマットで出力を生成するように LM に指示することがよくあります。
左の例は、reactフレームワークと呼ばれるフレームワークを用いて、思考の連鎖と呼ばれる推論を行うためにLMを使用した例です。
しかし、技術的な詳細は気にしないでください。
しかし、重要なのは、LMに考えるスペースを与えることで、より正確な結論が得られることが多いので、思考はLMが考えていることであるということです。
そして、具体的な行動を示すキーワードとしての「行動」、その行動から何を学んだかを示す「観察」、といった具合です。
そして、思考、行動、観察という特定のキーワードを使うように指示するプロンプトがあれば、このプロンプトとパーサーを組み合わせて、特定のキーワードでタグ付けされたテキストを抽出することができる。
このように、LM の入力を指定し、LM の出力をパーサが正しく解釈するという、非常に優れた抽象化を実現することができる。
それでは、lang chainを使った出力パーサーの例をご覧ください。
この例では、LM が JSON を出力し、lang chain を使ってその出力をパースする方法を見てみましょう。
この例では、製品レビューから情報を抽出し、その出力をJSON形式でフォーマットすることを想定しています。
そこで、どのように出力がフォーマットされるかの例を示します。
技術的には、これはPythonの辞書で、商品にプレゼントがあるかどうか、マスターフォール、配送にかかった日数は5日、価格値はかなり手頃なものでした。
もしこれが望ましいアウトプットの一例だとしたら、ここではカスタマーレビューの例と、そのJSONアウトプットに到達しようとするテンプレートを紹介します。
これがカスタマーレビューです。
このリードブロワーはとても素晴らしいです」と書かれています。
キャンドルブロワー、ジェンダーブリーズ、ウイニーシティ、トルネードの4つの設定があります。
賢明な記念日のプレゼントからちょうど2日で到着しました。
今までのスピーチリストの中で、妻が唯一使っているくらい気に入ってくれたようです。
そしてこちらは、指定されたすべての情報のうち、次のテキストを抽出するためのレビューテンプレートですこれは贈り物でした。
ということで、この場合は、これは贈り物なので、Yesとなります。
また、delivery days、配達にどのくらい時間がかかったか？この場合、右のように2日で届くようです。
価格帯は？リードブロワーで少し高いとか、そういうことですね。
だから、レビューのテンプレートは、OMに、私たちが顧客のレビューを入力して、これらの3つのフィールドを抽出し、次のキーでJSONとして出力をフォーマットするように依頼しました。
なるほど、なるほど。
では、これをラインチェーンでラップする方法を説明します。
チャットプロンプト・テンプレートをインポートしましょう。
実はこれ、先ほどすでにインポートしています。
このため、技術的に行が重複してしまいますが、ゲームをインポートして、レビュー・テンプレートからプロンプト・テンプレートを作成することにします。
これがそのプロンプトテンプレートです。
プロンプト・テンプレートの初期の使い方をまとめると、オープニング・アイ・エンドポイントに渡すメッセージを作成し、オープニング・アイ・エンドポイントを作成し、そのエンドポイントを呼び出し、レスポンスをプリントアウトしてみましょう。
ビデオを一時停止してコードを実行することをお勧めします。
そして、このようなものがあります。
配送日数は2日、価格もかなり正確に表示されています。
しかし、レスポンスのタイプを確認すると、これは実際には文字列であることに注意してください。
つまり、JSONのように見えて、キーと値のペアのように見えますが、実は辞書にはなっていません。
これはただの長い文字列なのです。
ですから、私が本当にやりたいことは、レスポンスのコンテンツにアクセスして、giveキーから値を取得することです。
しかし、これを実行すると、エラーが発生するはずです。
これはPythonの辞書ではありません。
では、これを実行するためにLankinのパーサーをどのように使うか見てみましょう。
Lankinからレスポンススキーマと構造化出力パーサーをインポートすることにします。
そして、レスポンス・スキーマを指定して、何を一時停止したいかを伝えます。
giveスキーマはgiftという名前で、説明文は購入した商品を他の人にあげるというものです。
はい」の場合はtrue、「いいえ」の場合はfalse、「不明」の場合はunknownといった具合に。
このようにgiveスキーマ、delivery dayスキーマ、price valueスキーマを用意し、この3つを以下のようにリストにまとめてみましょう。
さて、これらのスキーマを指定したことで、ランキンは実際にプロンプトそのものを、出力パーサーに、LMサーバーのどこにフォーマットの指示を印刷するかという指示を出させることができます。
彼女は、出力パーサーが処理できる縮退出力を引き起こす、LMに対するかなり正確な指示のセットを持っています。
そこで、新しいレビュー・テンプレートを用意しました。
レビュー・テンプレートには、Lankinが作成したフォーマット命令が含まれています。
このレビュー・テンプレートからプロンプトを作成し、オープンAIエンドポイントに渡すメッセージを作成します。
必要であれば、実際のプロンプトを見ることができます。
このプロンプトには、融合されたギフト配送日数価格値を抽出するための指示があります。
これがテキストで、これが書式設定の指示です。
最後に、open AIエンドポイントを呼び出すと、どんな応答が返ってくるか見てみましょう。
先ほど作成した出力パーサーを使えば、これを出力辞書にポーズすることができます。
これは文字列ではなく辞書タイプであることに注意してください。
このため、キーであるギフトに関連する値を抽出してtrueを取得したり、配送日に関連する値を抽出してtoを取得したり、価格値に関連する値を抽出したりすることができます。
このように、LMの出力をPythonの辞書にパースすることで、下流の処理で使いやすい出力にすることができるのです。
ビデオを一時停止してコードを実行することをお勧めします。
これで、これらのツールを使ったモデル、プロンプト、パーサは終わりです。
プロンプトテンプレートを再利用したり、プロンプトテンプレートを他の人と共有したり、プロンプトテンプレートに組み込まれたラインチェーンを使用することもできます。
プロンプトテンプレートは、出力パーサーと組み合わせることができ、特定の形式で出力する入力プロンプトをパーサーで一時停止してPython辞書にデータを格納したり、ダウンストリーム処理を容易にするためのデータを格納します。
次のビデオでは、LANがどのように優れたチャットボットを構築するのに役立つかを見ていきましょう。
